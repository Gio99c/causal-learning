{"cells":[{"cell_type":"markdown","metadata":{"id":"t-pdE-P1Imqt"},"source":["â“’ 2022 CCNets, Inc\n","\n","https://ccnets.org\n"]},{"cell_type":"markdown","metadata":{"id":"5JlD6_H8Imqw"},"source":["Authors : JinSu Kim, Jisu Hong, Yusang Park, Xiyana Figuera, JunHo Park"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"FcSXRhjkImqw"},"source":["Initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10781,"status":"ok","timestamp":1661594071144,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"cniR9JJTImqw","outputId":"a101fcde-dea3-4967-d291-39031db5e448"},"outputs":[],"source":["%pip install torch\n","%pip install torchvision\n","%pip install pillow\n","%pip install matplotlib"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":909,"status":"ok","timestamp":1661594072050,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"_e3AwuCNImqx"},"outputs":[],"source":["from __future__ import print_function\n","import argparse\n","import os\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import torch.nn.functional as F\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","from IPython import display\n","import time\n","\n","#CCNets init\n","# Convolutional nerual networks with resents having 10 layers\n","# from resnets_ccn import cnn_ResNet10 as cnn \n","# Transpose convolutional nerual networks with resents having 9 layers\n","# from resnets_ccn import transpose_cnn_ResNet10 as transpose_cnn\n"]},{"cell_type":"markdown","metadata":{"id":"VF7JsjZvImqy"},"source":["Inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":489,"status":"ok","timestamp":1661595823272,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"lewcr3xvImqy"},"outputs":[],"source":["#TODO: \n","MODEL_PATH = ''\n","\n","# Root directory for dataset\n","dataroot = \"/content\"\n","    \n","# Number of workers for dataloader\n","workers = 2\n","\n","# Batch size during training\n","batch_size = 32\n","\n","# Number of channels in the training images. For color images this is 3\n","n_img_ch = 3\n","n_img_sz = 128\n","\n","# number of dimensions of causal explanation vector in explantory space  \n","dim_explanation = 256\n","\n","# A dimension of labels \n","dim_label = 2\n","\n","# Learning rate for Celeb A images\n","lr = 0.0002 \n","\n","# Number of training epochs\n","num_epochs = 100\n","\n","# Learning rate for optimizers\n","step_size = 4\n","\n","# coefficients used for computing running averages of gradient\n","beta1 = 0.9\n","\n","# scheduler decay rate\n","gamma = 0.99954\n","\n","\n","ngpu = 2\n","\n","# Set random seed for reproducibility\n","manualSeed = 999\n","\n","# ManualSeed = random.randint(1, 10000) # use if you want new results\n","random.seed(manualSeed)\n","torch.manual_seed(manualSeed)\n","\n","# Decide which device we want to run on\n","device = torch.device('cuda:0' if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1661594072050,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"Ze3C371XTY-V"},"outputs":[],"source":["# Causal cooperative nets(CCNs) composed of an Explainer, a Reasoner, and a Procuder \n","'''-ResNet in PyTorch.\n","\n","For Pre-activation ResNet, see 'preact_resnet.py'.\n","\n","Reference:\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n","'''\n","class Explainer(nn.Module):\n","    def __init__(self, Net):\n","        super(Explainer, self).__init__()\n","        self.net = Net(n_img_ch, dim_explanation)\n","        self.sigmoid = nn.Sigmoid()\n","        self.n_img_ch = n_img_ch\n","        \n","    def forward(self, src):\n","        x = self.net(src)\n","        x = self.sigmoid(x)\n","        return x\n","\n","class Reasoner(nn.Module):\n","    def __init__(self, Net, n_img_sz, n_img_ch, n_label, n_explain):\n","        super(Reasoner, self).__init__()\n","        self.net = Net(n_img_ch + 1, n_label)\n","        self.sigmoid = nn.Sigmoid()\n","        self.n_explain = n_explain\n","        self.n_img_ch = n_img_ch \n","        self.n_img_sz = n_img_sz \n","        self.n_img_sz_2 = n_img_sz*n_img_sz \n","\n","    def forward(self, image, explain):\n","        e = explain.view([-1, self.n_explain, 1])\n","        e = e.repeat(1, 1, int(self.n_img_sz_2/self.n_explain))\n","        reshaped_e = torch.reshape(e, (-1, 1, self.n_img_sz, self.n_img_sz))  \n","        cat = torch.cat([image, reshaped_e], 1)\n","        y = self.net(cat)\n","        y = self.sigmoid(y)\n","        return y\n","    \n","class Producer(nn.Module):\n","    def __init__(self, Net, n_label, n_explain, n_img_ch):\n","        super(Producer, self).__init__()\n","        self.max_n = max(n_label, n_explain)\n","        self.net = Net(2*self.max_n, n_img_ch)\n","        self.tanh = nn.Tanh()\n","        self.n_label = n_label\n","        self.n_explain = n_explain\n","        \n","    def forward(self, label, explain):\n","        y = label.repeat(1, int(self.max_n/self.n_label))  \n","        e = explain.repeat(1, int(self.max_n/self.n_explain))  \n","        cat = torch.cat([y, e], 1)  \n","        x = self.net(cat)\n","        x = self.tanh(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"o6Zxgz9dImqz"},"source":["Labels"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1661594072050,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"O3c6dVMDImqz"},"outputs":[],"source":["#Characteristics of Celebs\n","\n","# 5_o_Clock_Shadow Arched_Eyebrows Attractive Bags_Under_Eyes Bald    ## 0~4  \n","# Bangs Big_Lips Big_Nose Black_Hair Blond_Hair                       ## 5~9  \n","# Blurry Brown_Hair Bushy_Eyebrows Chubby Double_Chin                 ## 10~14  \n","# Eyeglasses Goatee Gray_Hair Heavy_Makeup High_Cheekbones            ## 15~19  \n","# Male Mouth_Slightly_Open Mustache Narrow_Eyes No_Beard              ## 20~24  \n","# Oval_Face Pale_Skin Pointy_Nose Receding_Hairline Rosy_Cheeks       ## 25~29  \n","# Sideburns Smiling Straight_Hair Wavy_Hair Wearing_Earrings          ## 30~34  \n","# Wearing_Hat Wearing_Lipstick Wearing_Necklace Wearing_Necktie Young ## 35~39"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1661594072050,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"8IN2StqRImqz"},"outputs":[],"source":["'''-ResNet in PyTorch.\n","\n","For Pre-activation ResNet, see 'preact_resnet.py'.\n","\n","Reference:\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n","\n","[2] Modified by PARK, JunHo in April 10, 2022\n","\n","'''\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","    def __init__(self, in_planes, planes, transpose, stride=1):\n","        super(BasicBlock, self).__init__()\n","        kernel_size3 = 3\n","        kernel_size1 = 1\n","        if transpose is True and stride != 1:\n","            Conv2d = nn.ConvTranspose2d\n","            kernel_size3 += 1\n","            kernel_size1 += 1\n","        else:\n","            Conv2d = nn.Conv2d\n","\n","        self.conv1 = Conv2d(\n","            in_planes, planes, kernel_size=kernel_size3, stride=stride, padding=1, bias=False)\n","        \n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = Conv2d(planes, planes, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                Conv2d(in_planes, self.expansion*planes,\n","                          kernel_size=kernel_size1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, ninp, noutp, transpose):\n","        super(ResNet, self).__init__()\n","        self.expansion = 4\n","        if transpose is False:\n","            self.in_planes = 64\n","            self.layer1 = self._make_layer(BasicBlock, 64, transpose)\n","            self.layer2 = self._make_layer(BasicBlock, 128, transpose)\n","            self.layer3 = self._make_layer(BasicBlock, 256, transpose)\n","            self.layer4 = self._make_layer(BasicBlock, 512, transpose)\n","            self.nlast = 512\n","        else:\n","            self.in_planes = 512\n","            self.layer1 = self._make_layer(BasicBlock, 512, transpose)\n","            self.layer2 = self._make_layer(BasicBlock, 256, transpose)\n","            self.layer3 = self._make_layer(BasicBlock, 128, transpose)\n","            self.layer4 = self._make_layer(BasicBlock, 64, transpose)\n","            self.nlast = 64\n","        if transpose is True:\n","            self.linear = nn.Linear(ninp, 512, bias = False)\n","            self.conv1 = nn.ConvTranspose2d(512, 512, kernel_size=4, stride=4, padding=0, bias=False)\n","            self.bn1 = nn.BatchNorm2d(512)\n","            self.conv2 = nn.ConvTranspose2d(self.nlast*BasicBlock.expansion, noutp, kernel_size=2, stride=2, padding=0, bias=False)\n","        else:\n","            self.conv1 = nn.Conv2d(ninp, 64, kernel_size=2, stride=2, padding=0, bias=False)\n","            self.bn1 = nn.BatchNorm2d(64)\n","            self.linear2 = nn.Linear(self.nlast*BasicBlock.expansion, noutp, bias = False)\n","        \n","        self.transpose = transpose        \n","\n","    def _make_layer(self, block, planes, transpose):\n","        layers = []\n","        layers.append(block(self.in_planes, planes, transpose, stride = 2))\n","        self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        if self.transpose is True:\n","            x = self.linear(x)\n","            x = x.view([-1, 512, 1, 1])\n","        out = F.relu(self.bn1(self.conv1(x)))\n","\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","\n","        if self.transpose is False:\n","            out = F.avg_pool2d(out, 4)\n","            out = out.view(out.size(0), -1)\n","            out = self.linear2(out)\n","        else :\n","            out = self.conv2(out)\n","        return out\n","\n","def resNet10(ninp, noutp):\n","    return ResNet(ninp, noutp, transpose = False)\n","\n","def transpose_resNet10(ninp, noutp):\n","    return ResNet(ninp, noutp, transpose = True)\n"]},{"cell_type":"markdown","metadata":{"id":"3J1jWIPFImq0"},"source":["TrainLoader / DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13594,"status":"ok","timestamp":1661595850022,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"2ElR96PHImq0","outputId":"8c3e4f5a-debc-4cc0-9c42-63372db51264"},"outputs":[],"source":["# CelebA dataset\n","trainset = dset.CelebA(root=dataroot, split = \"train\", transform=transforms.Compose([\n","                            transforms.Resize(n_img_sz),\n","                            transforms.ToTensor(),\n","                            transforms.CenterCrop(n_img_sz),\n","                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","                        ]), download = True)\n","\n","# Get trainloader\n","def get_trainloader():\n","    return torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n"]},{"cell_type":"markdown","metadata":{"id":"EkGoQndNImq1"},"source":["CCNets Casual Learning Models"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4903,"status":"ok","timestamp":1661595273230,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"GyDIEtu7Imq1"},"outputs":[],"source":["# Intitialize the CCNs composed of an Explainer, a Reasoner, and a Producer\n","explainer = Explainer(resNet10).to(device)\n","reasoner = Reasoner(resNet10, n_img_sz, n_img_ch, dim_label, dim_explanation).to(device)\n","producer = Producer(transpose_resNet10, dim_label, dim_explanation, n_img_ch).to(device)"]},{"cell_type":"markdown","metadata":{"id":"te8GKAfpImq1"},"source":["Variables for debugging"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":472,"status":"ok","timestamp":1661595278359,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"PAqC3uBzImq1"},"outputs":[],"source":["# Variables related to print images for a debugging purpose\n","fig_len = 15\n","n_canvas_col = min(6, batch_size)\n","n_canvas_row = 4\n","m_empty_image = np.ones((n_img_ch, n_img_sz, n_img_sz))\n","m_img_canvas = np.ones((n_img_sz*(n_canvas_row+1), n_img_sz*(n_canvas_col), n_img_ch))"]},{"cell_type":"markdown","metadata":{"id":"_Yb4iUIcImq1"},"source":["Print images"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1661595279252,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"Y5ZdLhqpImq2"},"outputs":[],"source":["# Show images while debugging\n","def create_label_controlled_images(images, labels):\n","    src = images.to(device)\n","    label_cpu = labels.type(torch.float).clone()\n","\n","    with torch.no_grad():\n","        explains = explainer(src)\n","    m_img_canvas[:n_img_sz,:n_img_sz*(n_canvas_col)] = np.transpose(vutils.make_grid(images[:n_canvas_col], padding = 0, normalize=True), (1,2,0))\n","\n","    for i in range(n_canvas_row):\n","        controlled_labels_cpu = label_cpu.clone()\n","        for j in range(n_canvas_col):\n","            if i == 0:\n","                controlled_labels_cpu[j][0] = 0.\n","                controlled_labels_cpu[j][1] = 1.\n","            elif i == 1:\n","                controlled_labels_cpu[j][0] = 0.\n","                controlled_labels_cpu[j][1] = 0.\n","            elif i == 2:\n","                controlled_labels_cpu[j][0] = 1.\n","                controlled_labels_cpu[j][1] = 1.\n","            elif i == 3:\n","                controlled_labels_cpu[j][0] = 1.\n","                controlled_labels_cpu[j][1] = 0.\n","        controlled_labels = controlled_labels_cpu.to(device)\n","        with torch.no_grad():\n","            generated_images = producer(controlled_labels, explains).cpu()\n","        generated_images = generated_images[:n_canvas_col]\n","        m_img_canvas[n_img_sz*(i+1):n_img_sz*(i+2), :n_img_sz*(n_canvas_col)] = np.transpose(vutils.make_grid(generated_images, padding = 0,normalize=True), (1,2,0))\n","    return m_img_canvas"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1661595279253,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"gshwUQjLImq2"},"outputs":[],"source":["def print_figure(show_image):\n","    plt.figure(figsize=(fig_len, fig_len))\n","    plt.subplot(1, 1, 1)\n","    plt.imshow(show_image, interpolation=\"sinc\")\n","    plt.axis(\"off\")\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Ip7lj4myImq2"},"source":["Optimizers & Scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":752,"status":"ok","timestamp":1661595282544,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"hjvm8MvKImq2"},"outputs":[],"source":["# Init of optimizers and scheduler for the explainer, reasoner, and producer\n","momentum=0.9\n","\n","opt_explainer = optim.Adam(explainer.parameters(), lr=lr, betas=(beta1, 0.999))\n","opt_reasoner = optim.Adam(reasoner.parameters(), lr=lr, betas=(beta1, 0.999))\n","opt_producer = optim.Adam(producer.parameters(), lr=lr, betas=(beta1, 0.999))\n","\n","scheduler_explainer = optim.lr_scheduler.StepLR(opt_explainer, step_size=step_size, gamma=gamma)\n","scheduler_reasoner  = optim.lr_scheduler.StepLR(opt_reasoner, step_size=step_size, gamma=gamma)\n","scheduler_producer  = optim.lr_scheduler.StepLR(opt_producer, step_size=step_size, gamma=gamma)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1661595283338,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"tFmAEJEUImq2"},"outputs":[],"source":["# Update model parameters\n","def step_scheduler():\n","    scheduler_explainer.step() \n","    scheduler_reasoner.step()  \n","    scheduler_producer.step() "]},{"cell_type":"markdown","metadata":{"id":"liWhMf2wImq2"},"source":["Save models"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1661595287098,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"fXjW7VOVImq2"},"outputs":[],"source":["def save_models(model_path = MODEL_PATH):\n","    torch.save(explainer.state_dict(),os.path.join(model_path, 'explainer.pth'))\n","    torch.save(reasoner.state_dict(),os.path.join(model_path, 'reasoner.pth'))\n","    torch.save(producer.state_dict(),os.path.join(model_path, 'producer.pth'))"]},{"cell_type":"markdown","metadata":{"id":"w9qQD97ZImq2"},"source":["Set up training"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1661595288358,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"Jc105CRzImq3"},"outputs":[],"source":["# Set up training for each batch\n","\n","def requires_grads(require_grad = True):\n","    explainer.requires_grad_(require_grad)\n","    reasoner.requires_grad_(require_grad)\n","    producer.requires_grad_(require_grad)\n","\n","def zero_grads():\n","    explainer.zero_grad()\n","    reasoner.zero_grad()\n","    producer.zero_grad()\n","\n","def set_train():\n","    requires_grads(True)\n","    zero_grads()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":476,"status":"ok","timestamp":1661595293368,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"alxlI7jAImq3"},"outputs":[],"source":["def get_error(loss):\n","    return loss.mean().detach().cpu().item()"]},{"cell_type":"markdown","metadata":{"id":"Pr2XyUOVImq3"},"source":["Loss Function "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1661595294858,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"-_e3Wi2MImq3"},"outputs":[],"source":["_loss_L1 = nn.L1Loss(reduction='none')\n","_loss_L1_mean = nn.L1Loss(reduction='mean')\n","\n","# Calculate a loss value by L1 loss with mean reduction, and the target parameter detached(O)\n","def loss_function(prediction, target):\n","    return _loss_L1_mean(prediction, target.detach())\n","\n","# Calculate a loss value by L1 loss with no reduction, and the target parameter detached(O)\n","def error_function(prediction, target):\n","    return _loss_L1(prediction, target.detach())\n"]},{"cell_type":"markdown","metadata":{"id":"Uq6J-eVeImq3"},"source":["Backwards "]},{"cell_type":"markdown","metadata":{"id":"FWSHGOcCImq3"},"source":["Causal Training with a labeled dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1661595295585,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"yJqLngugImq3"},"outputs":[],"source":["# Causal Training(training mode A) of Causal Cooperative Nets(CCNs)\n","\n","# Source and target are a batch of images and labels\n","def causal_training(source, target):\n","\n","# Observation is the source in GPU\n","    observation = source.to(device)\n","# Label is the label in GPU\n","    label = target.type(torch.float).to(device)\n","\n","# Set up training for a batch\n","    set_train()\n","\n","# Explainer receives observation as an input and outputs causal explanation vector\n","    causal_explanation = explainer(observation)\n","    \n","# Reasoner receives observation and causal explanation as inputs and outputs inferred labels\n","    inferred_label = reasoner(observation, causal_explanation)\n","    ###################################################\n","\n","# Producer receives a label and a causal explanation as inputs and outputs generated observation\n","    generated_observation = producer(label, causal_explanation)\n","\n","# Producer receives an inferred label and a causal explanation as inputs and outputs reconstructed observation\n","# Causal explanation inputs to the producer is detached from the backward pass\n","    reconstructed_observation = producer(inferred_label, causal_explanation.detach())\n","    ###################################################\n","\n","# A set of prediction losses which are an inference loss, generation loss, and reconstruction loss \n","# Calcuated by prdiciton from output obervations and the intput obervations\n","# Batch reduction is set to mean when calculating the prediction losses\n","    inference_loss = loss_function(reconstructed_observation, generated_observation)\n","    generation_loss = loss_function(generated_observation, observation)\n","    reconstruction_loss = loss_function(reconstructed_observation, observation)\n","    ###################################################\n","\n","# Model errors of Explainer, Reasoner, and Producer calculated by a set of prediction losses\n","    explainer_error = error_function(inference_loss + generation_loss, reconstruction_loss)\n","    reasoner_error = error_function(reconstruction_loss + inference_loss, generation_loss)\n","    producer_error = error_function(generation_loss + reconstruction_loss, inference_loss)\n","    ###################################################\n","\n","# Compute gradients of the error function with respect to the parameters of Explainer, Reasoner, and Producer respectively.\n","# Error backpropagations of the model errors(Explainer error, Reasoner error, and producer error)x\n","# Through the propagtation paths created by the prediciton losses, \n","# Which are an inference loss, a generation loss, and a reconstruction loss\n","    explainer_error.backward(retain_graph = True)\n","    causal_explanation.detach_()\n","\n","    reasoner.zero_grad()\n","    producer.zero_grad()\n","    reasoner_error.backward(retain_graph = True)\n","    inferred_label.detach_()\n","\n","    producer.zero_grad()\n","    producer_error.backward(retain_graph = False)\n","\n","# Update model parameters \n","    opt_explainer.step()\n","    opt_reasoner.step()\n","    opt_producer.step()\n","\n","# Losses are prediction losses and erorrs are model errors \n","    losses = np.array([get_error(inference_loss), get_error(generation_loss), get_error(reconstruction_loss)]) \n","    errors = np.array([get_error(explainer_error), get_error(reasoner_error), get_error(producer_error)])\n","\n","    return losses, errors "]},{"cell_type":"markdown","metadata":{"id":"AderbDvtImq3"},"source":["Print losses & errors"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5135,"status":"ok","timestamp":1661595302066,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"8oQm_z6eImq3"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","logger = SummaryWriter(log_dir=f\"./logger/{step_size}\")\n","# Print prediction losses, and model errors while training\n","def print_training(epoch, num_epochs, idx, len_dataloader, errors, losses):\n","    print('[%d/%d][%d/%d]'\n","        % (epoch, num_epochs, idx, len_dataloader))\n","    print('loss\\t Inference: %.4f\\tGeneration: %.4f\\tReconstruction: %.4f'\n","        % (losses[0], losses[1], losses[2]))\n","    print('Explainer: %.4f\\tReasoner: %.4f\\tProducer: %.4f'\n","        % (errors[0], errors[1], errors[2]))\n","    \n","    logger.add_scalar(\"Train/Inference\", losses[0], epoch*len_dataloader+idx)\n","    logger.add_scalar(\"Train/Generation\", losses[1], epoch*len_dataloader+idx)\n","    logger.add_scalar(\"Train/Reconstruction\", losses[2], epoch*len_dataloader+idx)\n","    logger.add_scalar(\"Train/Explainer\", errors[0], epoch*len_dataloader+idx)\n","    logger.add_scalar(\"Train/tReasoner\", errors[1], epoch*len_dataloader+idx)\n","    logger.add_scalar(\"Train/tProducer\", errors[2], epoch*len_dataloader+idx)\n","\n","    logger.flush()\n","\n","        "]},{"cell_type":"markdown","metadata":{"id":"I-FDV4ZBImq3"},"source":["Traning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":427872,"status":"error","timestamp":1661595732171,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"kP1vmtUEImq3","outputId":"f5b04e30-628b-4b7e-9187-b2f386603dbb","tags":[]},"outputs":[],"source":["print(\"Starting Training Loop...\")\n","\n","pvt_time = time.time()\n","cnt_iter = 0  \n","\n","record_avg_error = []\n","record_avg_loss = []\n","\n","n_debug = 100\n","n_print = 50\n","\n","m_zeros3 = np.array([0., 0., 0.])\n","\n","previous_err = np.copy(m_zeros3)\n","previous_loss = np.copy(m_zeros3)\n","\n","for epoch in range(num_epochs):\n","    random.seed(pvt_time)\n","    torch.manual_seed(pvt_time)\n","\n","    dataloader = get_trainloader()\n","    len_dataloader = len(dataloader)\n","\n","    m_err_sum = np.zeros_like(np.arange(3), dtype=np.float64)\n","    m_loss_sum = np.zeros_like(np.arange(3), dtype=np.float64)\n","\n","    for i, (image_batch, label_batch) in enumerate(dataloader):\n","        indices = torch.tensor([20, 31]) # Male, Smiling\n","        label_batch = torch.index_select(label_batch, 1, indices)\n","        err, loss = causal_training(image_batch, label_batch)\n","\n","        m_loss_sum += loss\n","        m_err_sum += err\n","\n","        if i % n_debug == 0:\n","            display.clear_output(wait=True)\n","            show_image = create_label_controlled_images(image_batch, label_batch)\n","            print_figure(show_image)\n","            \n","# print the current learning rate of the Explainer, Reasoner, and Producer respectively\n","            print('Epoch-{0} lr_E: {1} lr_R: {2} lr_P: {3}'.format(epoch, \\\n","                opt_explainer.param_groups[0]['lr'], opt_reasoner.param_groups[0]['lr'], opt_producer.param_groups[0]['lr']))\n","            print_cnt = 0\n","\n","# For each n_print the iteration, print the training info.\n","        if i % n_print == 0:\n","            err_avg = m_err_sum/(i+1)\n","            loss_avg = m_loss_sum/(i+1)\n","\n","            print_training(epoch, num_epochs, i, len_dataloader, err_avg, loss_avg)\n","             \n","            cur_time = time.time()\n","            print ('Time for epoch {} is {} sec'.format(epoch + 1, cur_time - pvt_time))\n","            pvt_time = cur_time\n","            print_cnt += 1 \n","                    \n","            cnt_iter = 0 \n","            \n","        step_scheduler()   "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1661590576653,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"1v98YlOcImq4"},"outputs":[],"source":["print_figure(show_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1661590576653,"user":{"displayName":"Jisu Hong","userId":"04541679785374026606"},"user_tz":-540},"id":"eMeVcCddImq4"},"outputs":[],"source":["# Save model files in the local directory path \"MODEL_PATH\"\n","save_models(MODEL_PATH)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ccn_tutorial_1st_face_transform.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"metadata":{"interpreter":{"hash":"a7e81af88087f1f4bdc1f0426df14b24fa2673362c5daa7f7f9146748f40b3b1"}},"vscode":{"interpreter":{"hash":"2cf8fdb47089f97669c1c72ce8a5bd8ca276b27e56c180471de1e8e9cfe0d7da"}}},"nbformat":4,"nbformat_minor":0}
